---
title: "Tipología y ciclo de Vida de los datos. PRA2"
authors: Enrique Javier Andrés Orera & Sergio Fernández Bertolín
date: "04/01/2020"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Importación previa de librerías
```{r message= FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(kableExtra)
library(VIM)
library(arules)
library(car)
```

# 1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

El dataset corresponde a la colección de datos de entrenamiento parte de una competición activa de Kaggle y el objeto de esta competición es la realización de análisis predictivo sobre qué pasajeros sobrevivieron al naufragio del Titanic. 

# 2. Integración y selección de los datos de interés a analizar.

## Carga de datos y análisis inicial

Para empezar cargamos los datos. No hará falta integrarlos porque tenemos un único origen de datos, por lo que nos centraremos en el análisis y limpieza de estos. 

```{r carga, message= FALSE, warning=FALSE}
data.train<-read.csv("./titanic/train.csv",header=T,sep=",")
```

Hacemos una primera revisión de los datos, mirando la dimensión del data frame importado y las clases de cada variable del mismo
```{r analisis, message= FALSE, warning=FALSE}
# Breve análisis de los datos 
# Dimensiones de la base de datos mediante la función dim(). Obtenemos que disponemos de 891 registros o pasajeros (filas) y 12 variables (columnas). 
dim(data.train)
# Examinamos el tipo de datos con los que R ha interpretado cada variable.
sapply(data.train,class)
```
Vemos que nuestro dataset no es muy extenso, con tan sólo 891 individuos y 12 variables diferentes para trabajar. Como referencia, ponemos un breve diccionario que explica cada variable

## Data Dictionary

PassengerId -> id of de passenger

survived -> 0 = No; 1 = Yes

pclass -> Passenger Class	1 = 1st; 2 = 2nd; 3 = 3rd

name -> First and Last Name	 

sex -> Sex	 

age	-> Age	 

sibsp	-> Number of Siblings/Spouses Aboard	 

parch	 -> Number of Parents/Children Aboard	 

ticket	-> Ticket Number	 

fare -> Passenger Fare	 

cabin -> Cabin	 

embarked -> Port of Embarkation	C = Cherbourg; Q = Queenstown; S = Southampton

## Formato de variables

Examinamos distribución de valores por variables para ver si hay alguna que esté en un formato inadecuado

```{r formato, message= FALSE, warning=FALSE}
summary(data.train)
```
Observamos que tenemos 177 NA's en la variable Age, pero estos valores perdidos los trataremos en otro apartado. 
Reformateamos las siguientes variables para trabajar mejor con ellas

|Variable|Formato origen|Formato destino|
|--------|:------------:|--------------:|
|Survived|entero        |factor         |
|Pclass  |entero        |factor         |
|Sex     |string        |factor         |
|Ticket  |string        |factor         |
|Cabin   |string        |factor         |
|Embarked|string        |factor         |

```{r formato_cambio, message= FALSE, warning=FALSE}
#Survived de entero a factor
data.train$Survived <- factor(data.train$Survived, levels=c(0,1), labels=c("No", "Sí"))
levels(data.train$Survived)
#Pclass de entero a factor
data.train$Pclass <- factor(data.train$Pclass, levels=c(1,2,3), labels=c("Primera clase", "Segunda clase", "Tercera clase"))
levels(data.train$Pclass )
#R ha interpretado la variable Sex como un string, la cambiamos a factor
data.train$Sex<- factor(data.train$Sex)
levels(data.train$Sex)
#R ha interpretado la variable Ticket como un string, la cambiamos a factor
data.train$Ticket<- factor(data.train$Ticket)
head(levels(data.train$Ticket))
# R ha interpretado la variable Cabin como un string, la cambiamos a factor
data.train$Cabin<- factor(data.train$Cabin)
head(levels(data.train$Cabin))
# R ha interpretado la variable Embarked como un string, la cambiamos a factor
data.train$Embarked<- factor(data.train$Embarked, levels=c("C", "Q", "S"),labels=c("Cherbourg", "Queenstown", "Southampton"))
levels(data.train$Embarked)
```

Revisamos cómo ha quedado todo después de los cambios de formato
```{r revision_formato}
head(data.train)
sapply(data.train,class)
```

# 3. Limpieza de los datos

## 3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

Miramos el número de valores desconocidos y valores vacios por campo
```{r ceros}
sapply(data.train, function(x) sum(is.na(x)))
sapply(data.train, function(x) sum(ifelse(x=="", 1,0)))
```
En resumen vemos que tenemos 177 NAs en Age, 687 campos vacíos en Cabin y 2 en Embarked.

Cambiamos los campos vacíos por NAs, pues no tenemos ningún motivo para diferenciar estos de los NAs y tratarlos diferente.

```{r NA}
data.train$Cabin[data.train$Cabin==""]<- NA
data.train$Cabin[data.train$Embarked==""]<- NA
```

Imputaremos los valores que faltan basándonos en la similitud o diferencia entre los registros: la imputación basada en k vecinos más próximos

Imputamos los valores para Age y Embarked, en la variable Cabin hay demasiada poca información como para haCer imputaciones

```{r kNN}
suppressWarnings(suppressMessages(library(VIM)))
data.train$Age <- kNN(data.train[, 2:12] )$Age
data.train$Embarked <- kNN(data.train[, 2:12])$Embarked
summary(data.train)
```
Una vez resuelta la problemática de los valores vacios vemos cómo se distribuyen los valores de la edad y discretizamos esta variable para facilitar su análisis

```{r edad}
summary(data.train$Age)
# Discretizamos
data.train$AgeSegments <- cut(data.train$Age, breaks = c(0,10,20,30,40,50,60,70,110), labels = c("0-9", "10-19", "20-29",    "30-39","40-49","50-59","60-69","70+"))
```


## 3.2. Identificación y tratamiento de valores extremos.

Representamos un diagrama de caja por cada variable para ver qué valores distan mucho del rango intercuartílico (la caja) en las variables numéricas

```{r boxplots}
par(mar = c(2, 2, 2, 2))
layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE),widths=c(1,1,1), heights=c(1,1,1))
boxplot(data.train$Age,main="Age", col="gray")
boxplot(data.train$SibSp,main="Hermanos / cónyuges a bordo", col="gray")
boxplot(data.train$Parch,main="Padres / niños a bordo", col="gray")
boxplot(data.train$Fare,main="Tarifa", col="gray")
```

En ninguno de los casos los valores extremos que quedan fuera de los rangos parecen valores que no sean razonables. Quizás el que pueda levantar más sospechas es el valor altísimo que detectamos en la tarifa

Utilizamos la función boxplots.stats() de R para identificar los Valores extremos de Age y sus posiciones. Al ser pocos visualizamos el resto de variables de las personas en estos valores extremos
```{r extremos edad}
values <- boxplot.stats(data.train$Age)$out
idx <- which( data.train$Age %in% values)
Age.outliers <- data.train[idx,]
Age.outliers %>% kable(caption="Outliers en Age") %>% kable_styling(bootstrap_options = c("striped", "hover"))
```
Tras ver el resto de datos de estos pasajeros sigue pareciendo del todo razonable la edad registrada, por lo que decidimos no actuar sobre estos valores extremos

```{r extremos edad 2}
values <- boxplot.stats(data.train$Age)$out
idx <- which( data.train$Age %in% values)
Age.outliers <- data.train[idx,]
Age.outliers %>% kable(caption="Outliers en Age") %>% kable_styling(bootstrap_options = c("striped", "hover"))
```

Analizamos ahora los extremos en el número de hermanos
```{r extremos hermanos}
unique(boxplot.stats(data.train$SibSp)$out)
```
Los casos de 3 y 4 hermanos, aún siendo extremos los damos directamente por buenos, pues era muy frecuente ese número de hermanos en la época. Nos centramos en los casos de 5 y 8 hermanos para ver si son razonables

```{r extremos hermanos_5}
data.train[data.train$SibSp==5,c(3,4,6,9)]
```
En el caso de 5 hermanos vemos que coinciden ticket y apellidos, por lo que los damos por buenos.

Analizamos el caso de 8 hermanos
```{r extremos_hermanos_8}
data.train[data.train$SibSp==8,c(3,4,6,7,9)]
```

En este último caso vemos que se registran 8 personas a bordo, sólo hay 7 pero estamos tratando el data.train de esta competición de kraggle, el otro hermano está en el data.test, por lo que lo damos por bueno


Analizamos ahora los extremos en el número de familiares
```{r extremos familiares}
unique(boxplot.stats(data.train$Parch)$out)
```
Se registran como valores extremos todo lo que sea diferente a 0. Los pasajeros con 0 hermanos a bordo serán la norma, pero no parece descabellado que haya grupos de hermanos a bordo, por lo quedaremos directamente por buenos los valores diferentes a cero que no sean muy elevados. Como en el caso de los hermanos sólo inspeccionaremos los dos valores más extremos, en este caso 5 y 6.

```{r extremos parch 5}
data.train[data.train$Parch==5,c(3,4,6,7,8,9)]
```
Si miramos los datos de los tickets de las personas que tienen 5 familiares a bordo podemos detectar si hay alguna anomalía
```{r extremos parch 5 tickets}
data.train[data.train$Ticket=="347082",c(3,4,6,7,8,9)]
data.train[data.train$Ticket=="347077",c(3,4,6,7,8,9)]
data.train[data.train$Ticket=="382652",c(3,4,6,7,8,9)]
data.train[data.train$Ticket=="3101295",c(3,4,6,7,8,9)]
```

Parece todo correcto 

Miramos el caso de 6 familiares
```{r extremos parch 6}
data.train[data.train$Parch==6,c(3,4,6,7,8,9)]
```
```{r extremos parch 6 tickets}
data.train[data.train$Ticket=="CA 2144",c(3,4,6,7,8,9)]
```
En este caso parece todo correcto, pues faltarían un marido y un hijo que estarán en el data.test.

Para analizar los precios de los tickets lo haremos por clases en lugar de con toda la muestra, pues nos ayudará a identificar mejor las anomalías en esta variable
```{r extremos primera clase}
data.train.firstclass<-data.train[data.train$Pclass=="Primera clase",]
unique(boxplot.stats(data.train.firstclass$Fare)$out)
```
Todos los valores detectados están en órdenes de magnitud parecidos, excepto el que supera 500. Miramos este caso, pues los demás son totalmente aceptables
```{r extremos precio}
data.train[data.train$Fare>500,c(3,4,6,7,8,9,10)]
```
Tenemos aquí un valor que podría parecer sospechoso, pues pagan por 3 personas más del doble que cualquiera de los otros pasajeros con tickets similares. No obstante, contrastando los nombres de los pasajeros con los datos en Internet está registrado que pagaron 512 $ por sus billetes.

```{r extremos segunda clase}
data.train.secondclass<-data.train[data.train$Pclass=="Segunda clase",]
unique(boxplot.stats(data.train.secondclass$Fare)$out)
```
Para la segunda clase parecen del todo razonables los valores detectados como extremos 

Analizamos ahora la tercera clase

```{r extremos tercera clase}
data.train.thirdclass<-data.train[data.train$Pclass=="Tercera clase",]
unique(boxplot.stats(data.train.thirdclass$Fare)$out)
```
Aquí llama la atención los valores que superan los 50 dólares, pues serían muy altos incluso para la segunda clase. Miramos si hay muchas personas en el ticket y si no fuera así, deberíamos aplicar alguna corrección o marcarlos como "sospechosos"

```{r extremos tercera clase >50}
data.train.thirdclass[data.train.thirdclass$Fare>50,c(3,4,6,7,8,9,10)]
```

Observamos que estos precios corresponden con dos tickets de 7 personas cada una, por lo que consideramos que los valores son razonables.


# 4. Análisis de los datos

Añadimos dos nuevas variables para facilitar el análisis de la supervivencia, que es la variable en la que centraremos nuestro análisis

```{r variables}
# Añadimos variable FamilyMembers
data.train$FamilyMembers <- as.integer(data.train$SibSp + data.train$Parch + 1)
# Añadimos variable FarePerPassenger
data.train$FarePerPassenger <- data.train$Fare / data.train$FamilyMembers
# Discretizamos FarePerPassenger
data.train$FarePerPassengerSegments <- discretize(data.train$FarePerPassenger, method = "interval", breaks = 8)
```


Exportación de los datos preprocesados

```{r export}
write.csv(data.train, "./titanic/train_clean.csv")
```



Analizamos la supervivencia según las otras variables como exploración previa de los datos para seleccionar los grupos a analizar

```{r supervivencia}
# Survived como función de Sex
ggplot(data = data.train[1:dim(data.train)[1],],aes(x=Sex,fill=Survived))+geom_bar(position="fill")+scale_fill_manual(values=c("#FF0000","#008000"))+ylab("Frecuencia")+labs(title="Supervivencia por sexo")
#Survived como función de Embarked:
ggplot(data = data.train[1:dim(data.train)[1],],aes(x=Embarked,fill=Survived))+geom_bar(position="fill")+scale_fill_manual(values=c("#FF0000","#008000"))+ylab("Frecuencia")+labs(title="Supervivencia por puerto de embarque")
#Survived como función de AgeSegments:
ggplot(data = data.train[1:dim(data.train)[1],],aes(x=AgeSegments,fill=Survived))+geom_bar(position="fill")+scale_fill_manual(values=c("#FF0000","#008000"))+ylab("Frecuencia")+labs(title="Supervivencia por Edad")
#Survived como función de Pclass:
ggplot(data = data.train[1:dim(data.train)[1],],aes(x=Pclass,fill=Survived))+geom_bar(position="fill")+scale_fill_manual(values=c("#FF0000","#008000"))+ylab("Frecuencia")+labs(title="Supervivencia por Clase")
#Survived como función de FamilyMembers:
ggplot(data = data.train[1:dim(data.train)[1],],aes(x=FamilyMembers,fill=Survived))+geom_bar(position="fill")+scale_fill_manual(values=c("#FF0000","#008000"))+ylab("Frecuencia")+labs(title="Supervivencia por Family Members")
#Survived como función de FarePerPassengerSegments:
ggplot(data = data.train[1:dim(data.train)[1],],aes(x=FarePerPassengerSegments,fill=Survived))+geom_bar(position="fill")+scale_fill_manual(values=c("#FF0000","#008000"))+ylab("Frecuencia")+labs(title="Supervivencia por dinero pagado por pasajero")
```

## 4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar)

Tras mirar las distribuciones previas nos puede interesar comparar entre clases, entres sexos y entre puertos de embarque, por lo que creamos los distintos grupos que podemos utilizar

```{r subconjuntos}
# División en clases
primera_clase <- data.train[data.train$Pclass=="Primera clase",]
segunda_clase <- data.train[data.train$Pclass=="Segunda clase",]
tercera_clase <- data.train[data.train$Pclass=="Tercera clase",]
# División por supervivencia
sobrevive <- data.train[data.train$Survived=="Sí",]
no_sobrevive <- data.train[data.train$Survived=="No",]
# División por sexos
hombre <- data.train[data.train$Sex=="male",]
mujer <- data.train[data.train$Sex=="female",]
# División por puerto de embarque
southampton <- data.train[data.train$Embarked=="Southampton",]
cherbourg <- data.train[data.train$Embarked=="Cherbourg",]
queenstown <- data.train[data.train$Embarked=="Queenstown",]
```


## 4.2. Comprobación de la normalidad y homogeneidad de la varianza.

El siguiente paso será comprobar que nuestras variables cuantitativas tienen una distribución normal y que sus varianzas son homogéneas. Todas nuestras variables excepto Fare y Age son etiquetas descriptivas, por lo que sólo deberemos hacer los tests de normalidad homocedasticidad a estas dos.

Por el teorema del límite central podríamos asumir normalidad en todos los casos, pues siempre tenemos un número de muestras mayor que 30, pero vamos a asegurarnos. Aplcamis primero el test de Shapiro a ambas variables para comprobar si podemos rechazar la hipótesis nula de que la distribución no es normal con un intervalo de confianza del 95 %

```{r normalidad}
shapiro.test(data.train$Age)
shapiro.test(data.train$Fare)
```
En ambos casos obtenemos un p-valor mucho menos que 0.05, por lo que se comprueba que las distribuciones se asemejan mucho a una normal. 
Comprobamos ahora la homogeneidad de las varianzas con el test de Levene, que aplicaremos a las edades y precios en función de los grupos seleccionados como de interés. Empezamos con la edad.

```{r homocedasticidad edades}
leveneTest(data.train$Age~data.train$Pclass)
leveneTest(data.train$Age~data.train$Sex)
leveneTest(data.train$Age~data.train$Embarked)
leveneTest(data.train$Age~data.train$Survived)
```
Observamos que la edad presenta varianzas distintas según la clase (el p-valor es menor que 0.05 y rechazamos la hipótesis nula). 
En el caso del sexo, puerto de embarque y supervivencia tendríamos varianzas de edad muy similares para los distintos grupos de cada variable.

```{r homocedasticidad precios}
leveneTest(data.train$Fare~data.train$Pclass)
leveneTest(data.train$Fare~data.train$Sex)
leveneTest(data.train$Fare~data.train$Embarked)
leveneTest(data.train$Fare~data.train$Survived)
```
Para el caso de los precios observamos que el p-valor es muy pequeño (mucho menor que 0.05) para todas las variables estudiadas, por lo que podemos asumir que las varianzas de precios serán distintas para todos los grupos posibles según la clase, edad, sexo y supervivencia.

## 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. 

En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis,
correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

Vamos a hacer un test de hipotésis sobre la proporción de supervivientes dependiendo de la clase en la que viajaba el pasajero.

Hacemos un test sobre la proporción de supervivientes con 3 muestras, una para cada clase.
```{r est_2}
p_sob_primera <- nrow(primera_clase[primera_clase$Survived=="Sí",])/nrow(primera_clase)
p_sob_segunda <- nrow(segunda_clase[segunda_clase$Survived=="Sí",])/nrow(segunda_clase)
p_sob_tercera <- nrow(tercera_clase[tercera_clase$Survived=="Sí",])/nrow(tercera_clase)
sob <-  c(p_sob_primera*nrow(primera_clase),p_sob_segunda*nrow(segunda_clase),p_sob_tercera*nrow(tercera_clase))
nn <- c(nrow(primera_clase),nrow(segunda_clase),nrow(tercera_clase))
prop.test(sob,nn,alternative="two.sided",correct=FALSE)
```
El p-valor de 2.2e-16, mucho menor a 0.05, nos hace rechazar la hipótesis nula, por lo que podemos concluir que cada grupo tiene una proporción de supervivientes bastante diferenciada, centrada en los siguientes valores:


Primera clase: 62.96 % de supervivientes

Segunda clase: 47.28 % de supervivientes

Tercera clase: 24.23 % de supervivientes


En el test de correlación vamos a mirar primero las correlaciones entre sobrevivir y alguna variables numéricas

```{r corr}
data.train$SurvivedInt <- as.integer(ifelse(data.train$Survived=="Sí",1,0))
cor.test(data.train$FarePerPassenger,data.train$SurvivedInt)
cor.test(data.train$Age,data.train$SurvivedInt)
cor.test(data.train$SibSp,data.train$SurvivedInt)
```

Observamos cómo la correlación entre la edad, el número de hermanos o cónyugues y la supervivencia es prácticamente inexistente. En estos casos los p-valores son altos y la correlación bastante baja.

No obstante, para la dependencia de la supervivencia con el precio del billete por pasajero sí que hay un p-valor muy pequeño que permite rechazar la hipótesis nula y la correlación es de 0.22. Esta correlación no es excesivamente grande, pero teniendo en cuenta que sobrevivir es una variable binaria que da 0 o 1, una correlación de 0.22 será muy a tener en cuenta.

Para finalizar vamos a usar una regresión logística para predecir la probabilidad de supervivencia en función de las variables que hemos encontrado que puedan tener algún efecto en la misma. Nos decantamos por usar el sexo, el puerto de embarque, la clase y el precio.

```{r glm_cuanti_cuali}
glm_sobrevivir <- glm(formula =Survived~Sex+Embarked+Pclass+FarePerPassenger, family=binomial(link=logit),data=data.train)
summary(glm_sobrevivir)
```
Concluimos de este modelo que las variables que más influyen en la no supervivencia son ser hombre y ser de tercera clase, pues tenemos unos p-valores muy pequeños para ambas variables en el modelo.

Creado el modelo miramos la tabla de confusión de las predicciones hechas con el mismo y lo comparamos con las personas que han sobrevivido

```{r glm_pred_venta_2}
library(caret)
library(e1071)
predicted_data <- predict(glm_sobrevivir, data.train)
predicted_survival <- as.factor(ifelse(predicted_data>0.5,"Sí","No"))
cm <- confusionMatrix(predicted_survival,data.train$Survived)
cm$table
```
La exactitud del modelo es del 81.33 %. 523 valores son muertos reales y 200 son supervivientes reales del total de 891 resultados totales. El 81.33 % de las predicciones son correctas.

La precisión es elevada, del 88.49 %. El modelo predice bien las personas que sobreviven: 200 casos de supervivencia son correctos de los 226 que predecimos.

La especificidad es muy buena, del 95.26%. Esto quiere decir que el modelo predice muy bien las personas que NO van a sobrevivir, prediciendo 523 personas que mueren de las 549 que en realidad murieron.  

El peor de los parámetros de predicción es la sensibilidad, ya que de las 340 personas que en realidad sobreviven, tan sólo se detectan correctamente 200, un 58.82 %.

# 5. Representación de los resultados a partir de tablas y gráficas.

Representación de la curva ROC

```{r}
library(pROC)
r=roc(data.train$Survived,predicted_data , data=data.train)
plot(r)
auc(r)
```
El área por debajo de esa curva toma el valor de 0.8397, por lo que la habilidad del modelo para discriminar entre aquellos pasajeros que sobrevivieron y los que no, es buena.


Representamos gráficamente  la relación entre la supervivencia y cada uno de las siguientes variables  el sexo y la clase en la que viajaban, mediante diagramas de barras la cantidad de supervivientes y no supervivientes

Podemos comprobar gráficamente la conclusión que extrajimos, las variables que más influyen en la no supervivencia son ser hombre y viajar en tercera clase

```{r}
ggplot(data.train,aes(Sex ,fill=Survived))+geom_bar() +labs(x="Sex", y="Passengers")+
scale_fill_manual(values=c("#FF0000","#008000"))+ggtitle("Survived by Sex")
ggplot(data.train,aes(Pclass ,fill=Survived))+geom_bar() +labs(x="Class", y="Passengers")+
scale_fill_manual(values=c("#FF0000","#008000"))+ggtitle("Survived by Class")
ggplot(hombre,aes(Pclass ,fill=Survived))+geom_bar() +labs(x="Class", y="Male passengers")+
scale_fill_manual(values=c("#FF0000","#008000"))+ggtitle("Males survived by Class")
```

Tablas de contingencia

```{r}
SurvivedSex <- table(data.train$Sex, data.train$Survived)
SurvivedSex
prop.table(SurvivedSex, margin = 1)
SurvivedClass <- table(data.train$Pclass,data.train$Survived)
SurvivedClass
prop.table(SurvivedClass, margin = 1)
SurvivedSexbyClass <- table(data.train$Sex,data.train$Survived,data.train$Pclass)
SurvivedSexbyClass
prop.table(SurvivedSexbyClass, margin = 1)
```



# 6. Resolución del problema. Conclusiones.


Para la resolución realizamos las siguientes acciones y extrajimos las correspondientes conclusiones


#### Realizamos un test sobre la proporción de supervivientes con 3 muestras, una para cada clase, y concluimos que cada grupo tiene una proporción de supervivientes bastante diferenciada, centrada en los siguientes valores:


Primera clase: 62.96 % de supervivientes

Segunda clase: 47.28 % de supervivientes

Tercera clase: 24.23 % de supervivientes



#### Realizamos test de correlación entre sobrevivir y las variables numéricas FarePerPassenger, Age y SibSp, y concluímos que:

La correlación entre la edad, el número de hermanos o cónyugues y la supervivencia es prácticamente inexistente.

La correlación del precio del billete por pasajero y la supervivencia no es excesivamente grande, pero teniendo en cuenta que sobrevivir es una variable binaria que da 0 o 1, una correlación de 0.22 será muy a tener en cuenta



#### Realizamos una regresión logística para predecir la probabilidad de supervivencia en función de las variables que hemos encontrado que puedan tener algún efecto en la misma. Nos decantamos por usar el sexo, el puerto de embarque, la clase y el precio. Concluímos que:

La exactitud del modelo es del 81.33 %. 523 valores son muertos reales y 200 son supervivientes reales del total de 891 resultados totales. El 81.33 % de las predicciones son correctas.

La precisión es elevada, del 88.49 %. El modelo predice bien las personas que sobreviven: 200 casos de supervivencia son correctos de los 226 que predecimos.

La especificidad es muy buena, del 95.26%. Esto quiere decir que el modelo predice muy bien las personas que NO van a sobrevivir, prediciendo 523 personas que mueren de las 549 que en realidad murieron.  

El peor de los parámetros de predicción es la sensibilidad, ya que de las 340 personas que en realidad sobreviven, tan sólo se detectan correctamente 200, un 58.82 %.
